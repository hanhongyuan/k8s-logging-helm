input {

{{- if .Values.logstash_indexer.beats }}
  
  beats {
    port => 5045
  }

{{ else }}  

  kafka {
    bootstrap_servers => ["${KAFKA_BOOTSTRAP_SERVERS}"]
    topics => ["journals"]
    client_id => "${HOSTNAME}-journals"
    group_id => "journals"
    auto_offset_reset => "latest"
    consumer_threads => 10
    max_partition_fetch_bytes => '15728640'
  }  

{{- end }}

}

filter {
  
  json {
    skip_on_invalid_json => true
    source => "message"
  }
  
  mutate {
    add_field => { "id" => "%{[@metadata][_id]}" }
  }

  fingerprint {
     concatenate_sources => true
     source => ["@timestamp", "id"]
  }

}
output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST}"]
    user => "${ELASTICSEARCH_USER:\"\"}"
    password => "${ELASTICSEARCH_PASSWORD:\"\"}"       
    index => "journals-%{+YYYY.MM.dd}"
    manage_template => true
    template => "/usr/share/logstash/config/journals_template.json"
    template_name => "journals_1"
    template_overwrite => true
    ilm_enabled => "false"
  }
}